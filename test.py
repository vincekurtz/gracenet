#!/usr/bin/env python3

##
#
# GraceNET v0.0
#
# Predict future anomolies based soley on the past 12 months of 
# GRACE anomolies. This script loads a trained neural network and
# runs tests on other data.
#
##

# Multi-Layer Perceptron Regression system. 
# See http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html
from sklearn.neural_network import MLPRegressor
from sklearn.externals import joblib
from train import load_data, fit_sines
import matplotlib.pyplot as plt
from sin_approx import predict_next, get_sinusoid_params
from sklearn.metrics import r2_score
import numpy as np
import csv
from train import load_data
from sklearn.preprocessing import StandardScaler

def plot_stuff(x_example, y_example, predicted):
    """
    Plot a particular data point. Assume that x_example
    contains only the points leading up to y_example.
    """
    plt.plot(range(22), x_example)
    plt.plot(24, y_example, 'og')
    plt.plot(24, predicted, 'xr')
    plt.show()

def predict(x):
    """
    Return a prediction for the next value given 
    a set of variables for a single point.
    """
    prev_grace = x   # later this will change since other variables will be included
    sine_pred = predict_next(x)
    return sine_pred

def scatterplot(x_var, y_var):
    """
    Create a simple matplotlib scatterplot
    to see if we can establish a visual correlation between two
    variables.
    """
    plt.plot(x_var, y_var, '.')
    plt.show()

def validate():
    """
    Save csv of lat, lon, slope generated by the network
    """

    # load data for 2014-2016
    veg = []
    vegavg = []
    temp = []
    tempavg = []
    precip = []
    precipavg = []
    lat = []
    latlon = []   # store coordinates
    with open('validation.csv', 'r') as fh:
        reader = csv.reader(fh, delimiter=' ')
        for row in reader:
            if row[0] != "HDR":  # ignore header
                lat.append(row[1])
                # grace is row 2, but this is not part of the input
                precip.append(row[3])
                temp.append(row[4])
                veg.append(row[5])
                precipavg.append(row[6])
                tempavg.append(row[7])
                vegavg.append(row[8])

                latlon.append((row[0],row[1]))

    # load network
    net = joblib.load('parameters.pkl')

    # structure the input
    X = np.asarray([precip, precipavg, temp, tempavg, veg, vegavg, lat])
    X = X.transpose()

    # do feature scaling
    originalX, originalY = load_data("training_data.json")
    scaler = StandardScaler()
    scaler.fit(originalX)   # feature fit on the training data
    X = scaler.transform(X)  # but transform this validation data

    # predict on the network
    predicted = net.predict(X)

    # save the output to csv
    print("saving preditions to file")
    with open('network_predicted_2014-2016.csv', 'w') as fh:
        writer = csv.writer(fh, delimiter=' ')
        for i in range(len(predicted)):
            predicted_slope = predicted[i]
            lon = latlon[i][0]
            lat = latlon[i][1]
            writer.writerow([lon, lat, predicted_slope])



if __name__=="__main__":
    validate()
